{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from app.core.config import settings as config\n",
    "from app.utils.utils import split_docs\n",
    "from app.ingestion.web_loader.bs_loader import load_web_docs\n",
    "from app.ingestion.web_loader.bs_utils import urls\n",
    "from app.db.vector_db import VectorDB\n",
    "import os\n",
    "import pickle\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    wait_exponential,\n",
    "    stop_after_attempt,\n",
    "    retry_if_exception_type,\n",
    ")\n",
    "import requests\n",
    "from fastembed import SparseTextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(config.qdrant_url, api_key=config.qdrant_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_collection(\n",
    "    collection_name=config.qdrant_collection_name,\n",
    "    vectors_config={\n",
    "        \"dense\": models.VectorParams(\n",
    "            size=config.embeddings_dim, distance=models.Distance.COSINE\n",
    "        )\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(modifier=models.Modifier.IDF)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_collection(collection_name=config.qdrant_collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_FILE = \"all_docs.pkl\"\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    print(\"Loading cached documents...\")\n",
    "    with open(CACHE_FILE, \"rb\") as f:\n",
    "        all_docs = pickle.load(f)\n",
    "else:\n",
    "    all_docs = load_web_docs(urls)\n",
    "    print(\"Saving documents to cache...\")\n",
    "    with open(CACHE_FILE, \"wb\") as f:\n",
    "        pickle.dump(all_docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_docs(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(chunks))\n",
    "print(chunks[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = VectorDB(config)\n",
    "\n",
    "sparse_model = SparseTextEmbedding(\"Qdrant/bm25\")\n",
    "\n",
    "dense_embeddings = []\n",
    "sparse_embeddings = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(\n",
    "    retry=retry_if_exception_type((requests.exceptions.RequestException, Exception)),\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),  # Exponential backoff\n",
    "    stop=stop_after_attempt(5),\n",
    ")\n",
    "def get_embedding_with_retry(text):\n",
    "\n",
    "    dense_embedding = vector_db.get_embeddings(text)\n",
    "    sparse_embedding = list(sparse_model.embed([text]))[0]\n",
    "\n",
    "    return dense_embedding, sparse_embedding\n",
    "\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    try:\n",
    "        dense_embedding, sparse_embedding = get_embedding_with_retry(chunk.text)\n",
    "        dense_embeddings.append(dense_embedding)\n",
    "        sparse_embeddings.append(sparse_embedding)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i}/{len(chunks)} chunks\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed after retries on chunk {i}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dense_embeddings[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sparse_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache and Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSE_EMBEDDINGS_CACHE_FILE = \"dense_embeddings.pkl\"\n",
    "\n",
    "with open(DENSE_EMBEDDINGS_CACHE_FILE, \"wb\") as f:\n",
    "    pickle.dump(dense_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(DENSE_EMBEDDINGS_CACHE_FILE):\n",
    "    print(\"Loading cached dense embeddings...\")\n",
    "    with open(DENSE_EMBEDDINGS_CACHE_FILE, \"rb\") as f:\n",
    "        dense_embeddings = pickle.load(f)\n",
    "\n",
    "    # Regenerate sparse embeddings quickly\n",
    "    print(\"Regenerating sparse embeddings...\")\n",
    "    sparse_embeddings = []\n",
    "    for chunk in chunks:\n",
    "        sparse_embedding = list(sparse_model.embed([chunk.text]))[0]\n",
    "        sparse_embeddings.append(sparse_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dense_embeddings))\n",
    "print(len(sparse_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Embeddings to VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = vector_db.add_documents(\n",
    "    docs=chunks,\n",
    "    dense_embeddings=dense_embeddings,\n",
    "    sparse_embeddings=sparse_embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_info = vector_db.client.get_collection(vector_db.collection_name)\n",
    "print(f\"Collection info: {collection_info}\")\n",
    "\n",
    "# Count the number of points in the collection\n",
    "point_count = vector_db.client.count(vector_db.collection_name)\n",
    "print(f\"Number of documents in vector store: {point_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Query against VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is sutd?\"\n",
    "query_embedding = next(sparse_model.query_embed(query))\n",
    "results = vector_db.client.query_points(\n",
    "    collection_name=vector_db.collection_name,\n",
    "    query=models.SparseVector(**query_embedding.as_object()),\n",
    "    limit=3,\n",
    "    using=\"bm25\",\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is sutd?\"\n",
    "query_embedding = vector_db.get_embeddings(query)\n",
    "results = vector_db.client.query_points(\n",
    "    collection_name=vector_db.collection_name,\n",
    "    query=query_embedding,\n",
    "    limit=3,\n",
    "    using=\"dense\",\n",
    ")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-workflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
